\documentclass[10pt]{article}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{subfig} 
\usepackage{url}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage[table,dvipsnames]{xcolor}
\usepackage[counterclockwise]{rotating}
%\usepackage{lscape}

\let\oldbibliography\thebibliography
\renewcommand{\thebibliography}[1]{%
  \oldbibliography{#1}%
  \setlength{\itemsep}{-2pt}%
}
\definecolor{sun4}{HTML}{CCCCFF}
\newcommand{\ccg}[1]{\cellcolor{sun4}{#1}}
\newcommand{\rb}[1]{\raisebox{1.3ex}[-1.3ex]{#1}}
\newcommand{\thb}[1]{\multicolumn{1}{c}{\textbf{#1}}}
\newcommand{\thbr}[1]{\multicolumn{1}{c|}{\textbf{#1}}}

\begin{document}

\title{Feasibility and Performance of PQC Algorithms on Microcontrollers %
%\thanks{This work has been supported in part by NIST through
%Grant no. 70NANB18H219}%
} 

\author{Brian Hession \and Jens-Peter Kaps}

\date{ECE Department, George Mason University, Fairfax, VA 22030, U.S.A.\\
%\email{\{bhession jkaps\\
\url{http://cryptography.gmu.edu}}%
%}

\maketitle

\begin{abstract}
The eXtended eXternal Benchmarking eXtension (XXBX), which was originally developed
to support the Competition for Authenticated Encryption: Security, Applicability, 
and Robustness (CAESAR), is a tool that can measure the performance of cryptographic 
algorithms on a variety of microcontrollers. We expanded XXBX from supporting 
hashing algorithms and authenticated ciphers to include benchmarking of key encapsulation 
methods and signature schemes in order to support the NIST Post-Quantum
Cryptography (PQC) standardization process. 
This paper describes the changes to XXBX which were necessary to support PQC and 
presents the first results we obtained for a variety of PQC candidates.
This is a work in progress and more PQC algorithms will be benchmarked as 
microcontroller friendly implementations are becoming available.
\end{abstract}

%\keywords{XXBX, ARM, IoT, Quantum, Cryptography}

\section{Introduction}

With quantum computers developing at an increasing rate, it is important to take into 
consideration the security implications that may come along with the technological progress. 
Quantum algorithms will make possible breaking many of the encryptions and algorithms used for 
key sharing in a reasonable amount of time~\cite{nsareco}.
%FIXME we need a better reference than Wikipedia. Didn't NSA make a statement?
An effort to preemptively design and implement 
quantum resistant security is vital to maintain proper security standards.

There are many algorithms and key sharing protocols proven to be quantum resistant that have 
already been developed. However, libraries that implement such algorithms focus on x86 
architecture and benchmarking. Embedded devices and the Internet of Things (IoT) lack extensive 
development. In 2018, IoT devices connected to the Internet numbered close to 23.14 billion. 
By 2025, that number is predicted to be closer to 75.44 billion~\cite{2610}.
%FIXME also here we need something more tangible as reference. 
Such a large subset of Internet 
connected devices cannot be left behind during the rise of quantum computing.

Two such libraries implementing quantum resistant cryptography are known as libpqcrypto~\cite{libpqcrypto} 
and the Open Quantum Safe Project (liboqs)~\cite{openquantumsave}. These libraries, however, target 
x86 and x86\_64 based architectures specifically. There are few efforts keeping IoT devices 
up-to-date~\cite{MALINA2018462}.

Embedded devices each come with their own strict memory and power constraints making the 
implementation of such instruction-heavy algorithms a very complicated effort. One such 
cryptographic library exists for ARM Cortex-M4 architectures known as pqm4~\cite{PQM4}. 
However, even this library overlooks some of the memory constraints of many devices. 
There exist tools to help the development, testing, and benchmarking on these specific 
environments—for example, eXtended eXternal Benchmarking eXtension (XXBX)~\cite{PK15,Kap16}
(shown in Fig.\,\ref{fig:xxbx_setup}) which extends 
XBX~\cite{xbx} and SUPERCOP~\cite{SUP06}.  Since quantum computing is developing at an increased rate, 
it is vital for tools, such as XXBX, to keep up-to-date with the 
new emerging cryptographic standards.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=1.0]{../figures/xxbx-tilted}
    \caption{XXBX Setup}
    \label{fig:xxbx_setup}
\end{figure}

\section{XXBX Design}

XXBX can be broken into four parts: eXternal Benchmarking Software (XBS), eXternal 
Benchmarking Harness (XBH), eXternal Benchmarking Power (XBP), and 
eXternal Benchmarking Device (XBD) (see Fig.\,\ref{fig:xxbx_block}). 
The XBS is the software running on a PC that handles
the cross-compilation of cryptographic algorithms and orchestrates the benchmarking 
process. It interfaces with the XBH via Ethernet.  
The XBH acts as the control center and interface between the XBS and XBD. Additionally, it 
measures the execution time of each algorithm on the XBD and the power consumed with the 
help of the XBP. The XBP contains a current shunt and an amplifier to enable the XBH 
to obtain accurate current consumption readings. The XBD is the target device being benchmarked~\cite{xxbx}.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.8]{../figures/xxbx_block.pdf}
    \caption{Block Diagram of XXBX Components}
    \label{fig:xxbx_block}
\end{figure}

\subsection{Benchmarking Flow}
The XBS cross compiles the cryptographic algorithms that are to be benchmarked 
using a host of different compiler and linker options to ``test applications'' for the 
microcontroller on the selected XBD. 
Then the benchmarking is performed using the benchmarking flow depicted in Figure~\ref{fig:xxbx_flow}. 
The operations of \emph{Ecrypt}, \emph{Decrypt}, and \emph{Forged Decryption} are based on 
requirements for benchmarking Authenticated Encryption with Associated Data (AEAD) algorithms.
It starts by initiating a 
timing calibration of the XBH to make sure it can accurately convert the elapsed execution time
of an algorithm on the XBD to the number of clock cycles spent on the XBD.
It then runs several benchmarking runs on each application. 
For that, it uploads the application via TCP to the XBH.
The XBH forwards the executable to the XBD via I2C and commands the XBD to start 
running the application. It then sends cipher parameters such as key and message
to the XBD followed by a command to start the execution of the cryptographic
algorithm. Once received the XBD sends an ``execution start'' signal back to the
XBH upon which the XBH will start measuring the elapsed time.
The XBD will execute the uploaded benchmarking test cases and return the results. 
Along with the results, the XBD will send back
%FIXME: is this new? 
%the clock cycles taken to execute the benchmark as well as 
the total stack usage.
During the execution, the XBH measures the power usage at regular intervals by taking 
samples from the XBP. The XBD will signal the end of the execution through an 
``execution end'' signal to the XBH. The XBH will gather the power 
usage and results sent back from the XBD, package them, and send them back to the XBS 
for analysis.
If there are more parameter sets to be tested for this application, the test will 
continue. Else, the next application will be tested.
The XBS will take these results and check for success. If successful, the results are 
uploaded to a database for further analysis. 

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.6]{../figures/xxbx_flow.pdf}
    \caption{XXBX Execution Flow}
    \label{fig:xxbx_flow}
\end{figure}


\subsection{XBD Bootloader}
The XBD needs to be loaded with a small bootloader that is able to receive commands 
and respond to the XBH. The main commands used for execution are the following:

\begin{enumerate}
  \item\emph{Program Flash Request: }
     Loads the benchmarking test case application to the ROM.
  \item\emph{Timing Calibration Request: }
     Calibrates the timing differences between the XBH and the XBD to allow for proper 
     timing measurements.
  \item\emph{Start Application Request: }
     Switches the execution from the bootloader to the benchmarking test case application.
\end{enumerate}

\subsection{XBD Application}
The application can be considered an extension of the XBD bootloader code. These test 
cases are compiled with a specific cryptographic operation and algorithm. This creates 
portable code that sits within the ROM that the XBD switches to upon receiving the start 
application request.

A wrapper that the XBD bootloader understands connects the application and bootloader. 
To provide general support for all cryptographic operations, there only exists two buffers 
for execution of tests: parameter buffer and result buffer. The sizes of these buffers 
are decided at compilation and are unique to the cryptographic algorithm. It is up to the 
wrapper to compute the correct addresses of the parameters and results.

\subsection{XBS}
The XBS comprises of a collection of Python scripts. These scripts complete three main 
functions: compilation, execution, and data recording. 

A configuration file sets the cryptographic operation, the algorithm, the specific 
implementation to test, and the parameters needed to run the test. During compilation, 
the XBS grabs the specified implementation and the XBD wrapper code needed to execute 
the operation. Header files following the libcrypto format are generated and the code 
is compiled along with any dependencies that may be needed.
Upon a successful compilation, the database is initialized with the components needed 
to properly execute the tests. These components include the follow.

\begin{itemize}
  \item Operation
  \item Algorithm
  \item Implementation
  \item Parameters
  \item N columns of operation-specific details
\end{itemize}

During execution, the compiled application is loaded to the XBD for execution. 
A checksum is performed if the checksum file is present during compilation. The checksum 
test is essentially a test of sanity. It tests the algorithm for correctness and ensures 
it follows the expected behavior of the chosen cryptographic operation. Afterwards, the 
benchmarking is performed. The number of unique tests executed is equal to the number of 
parameter sets specified. The configuration can specify the number of trials to run per 
parameter set.

\subsection{XBH}
The XBH application controls the execution and behavior of the XBD. It receives commands 
from the XBS and translates and performs the specified actions on the XBD.

The device which the XBH code runs on must have a frequency equal to or greater than the 
device being benchmarked for correct results. Timing calibration is needed between the XBH 
and XBD to correctly estimate the number of clock cycles required to execute the cryptographic 
algorithm. When the start execution signal is received from the XBD, the XBH will start timing 
the execution and gather power usage statistics. This stops when the XBD sends the 
execution ended signal. At which point, the XBH translates the time taken to clock cycles 
on the XBD. It then asks for the results and stack usage from the XBD.
This all gets packaged and returned to the XBS for analysis.

\section{Adding Support for KEMs and Signature Schemes to XXBX}

For XXBX to be useful for benchmarking quantum-resistant cryptography, the functionality 
must be extended to include key encapsulation methods and signature schemes. This 
functionality is required in two separate parts of XXBX: XBS and XBD.

\subsection{Changes to the XBS}\label{sec:rom}
XBS needs to understand the structure and tests needed to support the new functionality. 
As noted before, XBS initializes the database with the components needed to properly 
execute the tests. During the execution stage, it grabs these components to forward 
to the XBH. A translation is needed here to package the data into something that XBD  
understands. Also, upon return, the data needs to be translated back into something XBS 
can analyze. This translation should be dependent on the operation but general enough to 
support many different implementations.

Each trial for KEMs run each of the modes of operation in the following order: key generation, 
encapsulation, decapsulation, decapsulation failure. For signature schemes, the order is 
similar: key generation, signing, opening/verifying, forgery detection. The next mode of 
operation depends on the results of the previous mode. Therefore it is important each mode 
returns successfully or the trial is cut short, deemed a failure, and continues on to the 
next trial.

The parameters to package differ based on the mode of operation. And because there are 
different modes, an extra variable is needed to specify which mode the XBD should run.

The structure of execution results expected back in return follows a similar design. 
Because both KEMs and signature schemes depend on the result of the previous mode, these 
structures need to be kept track of during the life of the trial. 

%FIXME: I did not include this picture as I did not understand it
%Fig. 2 depicts both the 
%structure of the parameters and the structure of the returned results.

For KEM key generation mode, no parameters are required -- just the mode of operation while 
the results include both the public and secret key. For KEM encapsulation mode, the 
public key is written to the ROM at the next available block after the application binary. 
A pointer to this location is provided as a parameter while the results include the session 
key and ciphertext containing the session key. Lastly, for KEM decapsulation, the secret key 
is written to ROM (overwriting the public key) and a pointer to its location is provided as 
an argument along with the ciphertext containing the session key.

Signature schemes are similar. For key generation, no parameters are required and both the 
public and secret key are returned. For signing, the secret key is written to ROM and a 
pointer to its location along with the message are passed while the signature is returned. 
Lastly, for opening/verifying, the public key is written to ROM and a pointer to its location 
and signature are provided while the results include the verified message.

%FIXME: Need to talk about the graph below in the text.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.8]{../figures/xxbx_pk.pdf}
    \caption{XXBX Public Key Process}
    \label{fig:xxbx_pk}
\end{figure}

\subsection{Changes to the XBD}
XBD needs to translate the Start Application Request instruction to the intended operation. 
In order to do so, the data or parameters received by the XBS must match a format expected 
by the XBD. In turn, the results of the test must be packaged in a format the XBS is expecting.

Prior to unpacking the parameters, the XBD has no idea which mode is being performed. 
Because of which, the same buffer sizes are allocated regardless of the mode of operation. 
Therefore, the ROM usage calculated during execution do not accurately reflect the differences 
between modes and should be considered a general size for the algorithm. 
The size of the buffers are the largest required of the different modes of operation.

Regardless of success, the length of the returned results does not differ. 
This is particularly useful for ensuring incorrect decapsulation and detecting signature 
forgeries on the XBS side.

Unlike the XBS, each execution is independent of the previous.
%FIXME: what do you mean by this sentence. Expand to make it more clear

\subsection{XBD Standalone}
An additional module was added to the XXBX structure. This XBD standalone mode creates 
an implementation of the algorithm in an environment without the XXBX overhead. It is a 
combination of XBD bootloader and XBD application stripped down to the core functions 
required to execute KEM and Signature operations.

This module automates the build process and allows for testing the algorithm in its purest 
form for accuracy instead of performance. It also allows for easy debugging with attached 
debuggers (such as GNU’s GDB).

Future work on this module will include an analysis of the stack during execution. 
In the typical XXBX environment, some of the stack is preserved for XBD application overhead. 
This module is designed to strip that overhead to its bare minimum and allow debuggers to 
test the logic of the implementation prior to running performance testing with XXBX. 
The automated build makes this process simple and extensible.


\section{Benchmarking Quantum-Resistant Public Key Cryptographic Algorithms}

%NIST released an initiative to design new quantum-resistant public key cryptographic 
%standards. The algorithms analyzed are many of the candidates submitted to NIST for 
%analysis. %FIXME: need to add citation to NIST PQC
From the submitted PQC candidates, we attempted to benchmark all algorithms for which the
combined size of the session key and the ciphertext do not exceed the RAM and for which the
public key and the secret key do not exceed the ROM available on the chosen XBD.

\subsection{Target Device}

Table~\ref{tab:XBDs} shows the microcontroller boards currently supported by XXBX and in 
{\color{purple}purple} the controllers that will be supported in the near future. 
The EK-TM4C123GXL board was chosen to benchmark the PQC algorithms using XXBX. 
It is currently the best supported ARM Cortex M4F based board by XXBX and represents a 
rather typical amount of memory, large enough to 
work with a decent variety of algorithms. 
Before August, we plan to benchmark the PQC algorithms also on the MSP-EXP432P401R 
which has double the amount of RAM and an ultra-low power ARM core and the
STM32F407G-DISC which is the board used by pqm4~\cite{PQM4}.
The amount of memory on the microcontroller is one limiting factor in benchmarking
PQC algorithms. In order to expand the amount of PQC algorithms that can be 
benchmarked we are also planning to support the MSP-EXP432P4111 board which has 
the most memory of all platforms shown in table~\ref{tab:XBDs}.

\begin{table}[ht]
  \caption{Currently Supported XBDs, {\color{blue}XBD used in this paper}, and {\color{purple}XBDs planned for future support}}\label{tab:XBDs}
    \begin{tabular}{l|c|ll|rrc|rr|r}
    \textbf{Board}   & \textbf{Manuf.}&\textbf{CPU}&\textbf{ISA}&\textbf{Bus}&\thb{f}&\textbf{HW}&\textbf{ROM}&\textbf{RAM} \\ \hline
%    Homemade         & Atmel     & ATmega1284P    &  AVR        &  8-bit &  20\,MHz &     &     &        \\
    MSP-EXP430F5529  & TI        & MSP430F        &  MSP430X    & 16-bit &  25\,MHz &     &   12kB &  10kB  \\
    MSP-EXP430FR5994 & TI        & MSP430FR       &  MSP430X    & 16-bit &  16\,MHz & AES &  256kB &   8kB  \\
    MSP-EXP432P401R  & TI        & ARM Cortex M4F &  ARMv7E-M   & 32-bit &  48\,MHz & AES &  256kB &  64kB  \\
    \color{purple}MSP-EXP432P4111  & TI        & ARM Cortex M4F &  ARMv7E-M   & 32-bit &  48\,MHz & AES & 2048kB & 256kB  \\
    \color{blue}EK-TM4C123GXL    & TI        & ARM Cortex M4F &  ARMv7E-M   & 32-bit &  80\,MHz &     &  256kB &  32kB  \\ 
    EK-TM4C129EXL    & TI        & ARM Cortex M4F &  ARMv7E-M   & 32-bit & 120\,MHz & AES & 1024kB & 256kB  \\ 
    NUCLEO-F091RC    & STM       & ARM Cortex M0  &  ARMv6-M    & 32-bit &  48\,MHz &     &  256kB &  32kB  \\
    NUCLEO-F103RB    & STM       & ARM Cortex M3  &  ARMv7-M    & 32-bit &  72\,MHz &     &  128kB &  20kB  \\
    \color{purple}STM32F407G-DISC1 & STM       & ARM Cortex M4F &  ARMv7E-M   & 32-bit & 168\,MHz &     & 1024kB & 192kB  \\
%    chipKIT uC32     & Microchip & PIC32MX3xx     &  MIPS32 M4K & 32-bit &  80\,MHz &     &     &     &   \\
    \end{tabular}
\end{table}


\subsection{Algorithm Selection}
%FIXME: this section needs more text, at least a classification of the algorithms
% and a table listing them and their parameters, e.g. your Table IV with 
% additional columns. Put all tables in LibreOffice, I'll convert them to LaTeX

The next ``down-selection'' came when trying to compile the algorithms. 
SUPERCOP has a repository of KEM and Signature implementation that fit the XXBX structure. 
This repository has many of the candidates for the new post-quantum standard. 
However, some of these algorithms are not capable of being built in embedded 
environments--particularly because of operating system calls or reliance on 
libraries such as openssl.
%FIXME: please check the last statement (made by me)

Some additional implementations were pulled from pqm4 to replace those in SUPERCOP. 
Pqm4 has included some libraries and implementations of common dependencies required by 
a lot of these algorithms that work with the Cortex-M4 architecture~\cite{PQM4}. Pqm4 focused on 
Level III algorithms, so some work was required to fit Level I and Level V versions. 
At the time of benchmarking, pqm4 contained only round 1 versions of the algorithms.

%FIXME: This section requires a little bit of work clarifying what we actually tested
% and including what we want to test by August. First and foremost, can you benchmark
% the latest, round 2, pqm4 algorithms?

Finally we implemented \texttt{\_sbrk()} system calls which are needed by all 
types of \texttt{alloc} functions to enable dynamic memory allocation which several 
algorithms require.

Table~\ref{tab:sizeskem} list the KEM candidates we are able to benchmark sorted by 
their respective security levels defined by NIST~\cite{pqccfp}.  
%For KEM algorithms, only levels I, III, and V apply. For signature schemes, all levels 
%technically apply.

\begin{table}[ht]
  \centering
  \caption{KEMs than run on XXBX and their key sizes in bytes}\label{tab:sizeskem}
    \begin{tabular}{l|c|c|rrrr}
                   & \textbf{Security} &             & \textbf{Public} & \textbf{Secret} & \textbf{Session} & \\ 
\textbf{Algorithm} & \textbf{Level} & \textbf{Type} & \textbf{Key} & \textbf{Key} & \textbf{Key} & \textbf{Ciphertext} \\ \hline
babybear	& 2	         & Lattice &  804       &   40       & 32          &  917 \\
kyber512	& 1	         & Lattice &  736       & 1632       & 32          &  800 \\
lightsaber	& 1	         & Lattice &  672       & 1568       & 32          &  736 \\
newhope512cca	& 1	         & Lattice &  928       & 1888       & 32          & 1120 \\
ntrukem443	& 1	         & Lattice &  611       &  701       & 32          &  611 \\
sikep503	& 1	         & Isogeny &  378       &  434       & 16          &  402 \\
mamabear	& 4	         & Lattice & 1194       &   40       & 32          & 1307 \\
kyber768	& 3	         & Lattice & 1088       & 2400       & 32          & 1152 \\
saber    	& 3	         & Lattice &  992       & 2304       & 32          & 1088 \\
papabear	& 5	         & Lattice & 1584       &   40       & 32          & 1697 \\
kyber1024	& 5	         & Lattice & 1440       & 3168       & 32          & 1504 \\
firesaber	& 5	         & Lattice & 1312       & 3040       & 32          & 1472 \\
newhope1024cca	& 5	         & Lattice & 1824       & 3680       & 32          & 2208 \\
    \end{tabular}
\end{table}

Unfortunately, most PQC signature algorithms exceed the RAM constraints of our 
target device. qTesla-I does work in the 
XBD-Standalone module but fails with the XBD application overhead. Therefor, we
were not able to benchmark any PQC signature algorithm.

An additional hurdle in benchmarking with XXBX is that 
the XBS network connection to the XBH will timeout during very long calculations on 
the XBD device. This will typically happen around 40 minutes or so.
Due to this, sikep751 and sphincss128shake256 which took more than 1.5 hours
could not be benchmarked.
%FIXME: This is to small for its own section. But a section on what we observed 
%during the tests might be good and can include other observations including more
%reasons on why certain algorithms won't run. Actually, it should also be 
%merged with the next section.

%\subsection{Target Device Signature Constraint}
%The target device has available 32 kB of RAM. Most of the post-quantum signature 
%algorithms exceed this constraint. Memory usage statistic from pqm4 are show below [6].
%Most of the algorithms noted above exceed 32 kB worth of RAM. qTesla-I does work in the 
%XBD-Standalone module but fails with the XBD application overhead.

\section{Results}

XXBX allows us to benchmark the algorithms with respect to ROM usage, RAM usage,
speed (in clock cycles), and energy consumption. 
There are four categories of results: ROM usage, RAM usage, speed (in clock cycles), 
and energy consumption.

The results for memory usage are shown in Fig.\,\ref{fig:rom} and Fig.\,\ref{fig:ram} for
ROM and RAM respectively. ROM usage includes the size of the executable as well as the 
size for the key written to ROM (see Sect.~\ref{sec:rom}). 
%FIXME: please verify
The RAM results are based on the stack usage reported by XXBX. It can be seen that
algorithms with larger Ciphertext sizes (see Table~\ref{tab:sizeskem}) are also consuming
more RAM, however there are some notable exceptions. Papabear, and both newhopes consume
less RAM for their key sizes than others.


\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.8]{./figures/rom.pdf}
    \caption{ROM Usage}
    \label{fig:rom}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.8]{./figures/ram.pdf}
    \caption{RAM Usage Based on Stack Usage}
    \label{fig:ram}
\end{figure}

The number or clock cycles required varies widely from algorithm to algorithm. The
only way to show differences between faster algorithms is by using a logarithmic scale
as can be seen in Fig.\,\ref{fig:clock}. Sike is the slowest by orders of magnitude.
Also the three bears are slow. In both cases we used the non optimized reference 
implementations. The bears seem to take the most time during the noise calculations,
in particular the \texttt{mac()} function--multiply and accumulate.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.8]{./figures/clock.pdf}
    \caption{Clock Cycles}
    \label{fig:clock}
\end{figure}

Due to the very large variation in number of clock cycles required between algorithms, 
the amount of energy consumed varies also by several order of magnitudes. However,
the advantage in terms of clock cycles required for the sabers is even more dominant
when it comes to energy consumption. The reason still needs to be investigated.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.8]{./figures/energy.pdf}
    \caption{Energy Usage}
    \label{fig:energ}
\end{figure}


%FIXME: After running Round 2 from pqm4 we need to generate a comprehensive result
%table and graphs. Please to all of this in LibreOffice, I'll convert and extract them.

%FIXME: What is most important here is a discussion and analysis of the results. That 
% is currently completely missing. E.G why are the three bears so slow, etc.
% Don't save that for the conclusion.

\section{Conclusion}

For embedded environments, the strict constraints due to limited memory size and power 
consumption makes developing IoT devices complicated. If execution time or power consumption 
are of greatest concern, both Kyber, New Hope, and Saber implementations are good candidates 
for KEM algorithms. However, if memory usage is of greatest concern, the Three Bears algorithm 
works better.

Sike takes an incredible amount of time to execute and is not a viable implementation for 
embedded environments.
XXBX is simple and adaptable. It will help users shift current cryptographic standards over 
to quantum-resistant public key cryptography in embedded environments.


\bibliographystyle{IEEEtran}
\bibliography{pqc-xxbx}


\end{document}

